[toc]

# 项目整体框架

<img src="https://gitee.com/wuqiongjin/noteimage/raw/master/Notebook_Image/202203022019666.png" alt="image-20220302201949544" style="zoom:80%;" />

&emsp;每个线程都有**自己专属的ThreadCache**(TLS无锁访问)，每次只需要向ThreadCache申请内存即可。ThreadCache的结构是一个哈希桶，每一个桶的位置存放的都是一个自由链表，不同桶中自由链表中所挂的对象大小不同。这里的对象都是定长对象，也就是说当线程向ThreadCache申请内存时，会传入一个对象的大小，ThreadCache通过传入的对象大小计算出桶的位置，随后将对应桶的下面的自由链表中的一块内存Pop出来给线程。

&emsp;如果ThreadCache对应桶中的自由链表没有小块对象了，那么ThreadCache会向CentralCache索要小块对象。CentralCache的结构也是一个哈希桶，不过每个桶下面挂的是一个SpanList，SpanList是由Span结构体组成的链表。每个Span当中存有描述这个Span的信息：当前的Span所管理的空间所对应的页号与页数、Span分出去的小块对象的数量、Span下面还挂着一个freelist以用来存储切分好的小块对象。那么ThreadCache在向CentralCache索要小块对象时，应该向哪个桶中的SpanList索要呢? 这里的桶的位置的也是依靠小块对象的大小确定的，也就是说CentralCache中桶下标的映射规则与ThreadCache是一致的，都是通过对象的大小来确定的。在得到桶的位置后，去遍历SpanList找寻非空的Span(非空指freelist不为空，因为freelist下面挂着小块对象，如果freelist中是空的，那么说明当前的Span已经将所有的小块对象都分出去了。一个没分出去任何小对象的Span下面的freelist一定挂着很多小对象(因为申请新的Span后就会对Span进行切分，随后将其挂载到Span下面的freelist当中))。找到非空的Span后，从非空的Span下面的freelist当中PopRange出一段小对象连接成的空间(虽然每次线程只要一个对象，但是CentralCache往往会给ThreadCache不止一个，这个数量是由MaxSize和batchNum共同决定的)。将这段小对象连接成的内存头插到ThreadCache对应桶中的freelist下(注意这段小对象链表的第一个小对象直接返回即可，因为线程需要马上使用，而剩下的要头插到ThreadCache的freelist下)。

&emsp;如果CentralCache对应桶下没有非空的Span了，那么它会向PageCache索要Span。PageCache的结构也是一个哈希桶，不过和前面两层不同，哈希桶的下标的映射规则是依靠页数来映射的。前面说过Span当中存有页数这个信息，也就是说页数是多少就代表桶的下标是多少！我们将桶的大小设位129，桶的下标从0-128，而0号桶没有意义就不使用了。每个桶的下面挂的也是一个SpanList，而这里的SpanList的Span是还没有切分的哦！切分Span的操作是在CentralCache中的GetOneSpan函数中做的！我们从页数对应的桶中头删一个Span，如果SpanList是空的，那么我们继续搜索后面的桶，如果再后面的桶中找到了非空的SpanList，那么就切分处一块Span。如果后面的桶也全是空的，此时需要向堆索要一块大小为128页的Span并插入到最后一块桶。然后递归调用自己，再次查询后面非空的桶，最终一定会将128页的这个Span进行切分的。(这里使用递归的原因是更好的复用了代码，虽然效率稍微下降了一丢丢，但是这一丢丢不影响)。在拿到Span后，返还给CentralCache，CentralCache对Span进行切分，然后返回给ThreadCache一批小对象。最终刚完成了内存申请的过程。

----

&emsp;我刚才所谈的只是内存申请的过程，并且像哪一层需要加锁，加的锁是什么锁，都没有细说。详细的细节看后面。

内碎片：

外碎片：





# ThreadCache

## 框架结构与成员变量

&emsp;thread cache是哈希桶的结构，每个桶实际上是一个按桶位置映射大小的内存块对象的自由链表。每个线程都会有一个自己的thread cache对象，这样每个线程在这里获取对象和释放对象时都是无锁的。





## 申请内存

### 向上对齐

&emsp;每个ThreadCache管理256KB的空间，为了更合理的管理，我们不能以1字节为单位进行对齐，这样的话一个ThreadCache就需要建立25w个自由链表了(**每个自由链表管理的对象大小都不同**)。因此我们采用更大字节数进行对齐，比如我们按照8字节来对齐，这样的话就需要建立256\*1024/8个自由链表了，实际上数目也有3w多，并且这种只按照8字节进行对齐的话，我们会发现划分空间时，内碎片的占比浮动很大。比如在字节数小的时候，假设我们索要2字节的空间，那么内碎片就占了(8-2)/8 = 75%；而当字节数大的时候，假设索要801字节的空间，那么内碎片占了(808-801)/808 = 0.8%左右。

---

这里先解释一下**向上对齐**，以便后续理解。

&emsp;当我们按照8字节来进行对齐时，会出现2种情况，一种是能够正好能整除8；另一种是不能整除8。当不能整除8时，我们就要进行向上对齐，就像结构体那样，需要浪费几个字节的空间。比如：当我们申请14字节时，实际上就是向第二个*(字节数从9-16映射到这个16字节的桶上)*自由链表去申请空间，申请1块大小位16字节的。再比如我们要申请129字节的空间，129属于[129, 1024]区间，因此采用16字节来对齐，而129不能整除16，因此要向上对齐，下一个能整除16的是144，因此他需要向*(字节数从129-144会映射到这个144字节的桶上)*自由链表申请空间，申请1块大小为144字节的。

---

&emsp;为了**均衡内碎片浪费的比例**以及**建立的自由链表的数目**(哈希桶的大小)，我们采用**不同的空间大小按照不同的字节数目来进行对齐**。

按照下面的范围划分以及不同范围字节数的对齐方式，能让整体控制在10%左右的**内碎片**浪费

|     申请的空间范围      |  对齐的字节数   |   自由链表的序号   |
| :---------------------: | :-------------: | :----------------: |
|         [1,128]         |    8字节对齐    |  freelist[0, 16)   |
|      [128+1, 1024]      |   16字节对齐    |  freelist[16, 72)  |
|    [1024+1, 8\*1024]    |   128字节对齐   | freelist[72, 128)  |
|  [8\*1024+1, 64\*1024]  |  1024字节对齐   | freelist[128, 184) |
| [64\*1024+1, 256\*1024] | 8\*1024字节对齐 | freelist[184, 208) |



**<font size="4">• 代码部分</font>**

&emsp;``RoundUp()``计算的是"**对齐到每块对象的大小为alignNum的自由链表上**"。比如14字节经计算后就会返回 从管理每块对象大小为16字节的自由链表上返回一块大小为16字节的对象。

这里解释一下``_RoundUp中的代码``。

举个例子，假设bytes是3字节，那么alignNum就是8字节。

32 16 8 4 2 1
      0 0 1 1      ``bytes``
      1 0 1 0      ``bytes + alignNum - 1``
\-------------------
        1 1 1	  ``alignNum - 1``
      1 0 0 0      ``~(aligNum - 1)``
\-------------------
      1 0 0 0      ``(bytes + alignNum - 1) & ~(alignNum - 1)``

**解释**：``~(alignNum - 1)``的目的是为了消除后面的零散位，同时保留最高位。而``bytes + alignNum``保证了它是向上对齐了，而``bytes + alignNum - 1``的-1则是让本身能够整除alignNum的数不会到下一个对齐数上。

```cpp
// 管理 空间范围划分与对齐、映射关系 的类
class SizeClass
{
public:
	static inline size_t _RoundUp(size_t bytes, size_t alignNum)	//align对齐数
	{
		//易于理解的写法
		//if (bytes % alignNum != 0)
		//{
		//	return (bytes + alignNum) / alignNum * alignNum;
		//}
		//else
		//{
		//	return bytes;
		//}

		//更优秀的写法
		return ((bytes + alignNum - 1) & ~(alignNum - 1));
	}

	static inline size_t RoundUp(size_t bytes)
	{
		if (bytes <= 128)
			return _RoundUp(bytes, 8);
		else if (bytes <= 1024)
			return _RoundUp(bytes, 16);
		else if (bytes <= 8 * 1024)
			return _RoundUp(bytes, 128);
		else if (bytes <= 64 * 1024)
			return _RoundUp(bytes, 1024);
		else if (bytes <= 256 * 1024)
			return _RoundUp(bytes, 8 * 1024);
		else
			assert(false);	//不在这个范围的，直接报错
        return 0;
	}
};
```

&emsp;

&emsp;

### 自由链表的下标

&emsp;我们知道申请空间的字节数，现在要根据这个字节数算出应该去找哪个自由链表。然而由于不同的字节数范围，它们所采取的对齐数的值是不同的，因此我们要对不同范围的字节数进行判断，然后再计算它是哪个自由链表的。

比如：14字节大小，它是属于8对齐数的，因此是``14/8=1``，是下标位1的自由链表。
再比如：129字节大小，它是属于16对齐数的，但是由于前面的128字节是按照8对齐数进行对齐的，与16字节对齐的方式不同，因此我们不能直接的使用129/16，而是应该使用(129-128)/16，这是计算在16对齐数规则下的字节数，随后要再加上按照8字节对齐的自由链表的下标号(这个号是固定的: 16)。

**• 代码部分**

```cpp
class SizeClass
{
public:
	//易于理解的写法
	//static inline size_t _Index(size_t bytes, size_t align_shift)
	//{
	//	if (bytes % (1 << align_shift) == 0)
	//	{
	//		return bytes / (1 << align_shift) - 1;
	//	}
	//	else
	//	{
	//		return bytes / (1 << align_shift);
	//	}
	//}

	//bytes是字节数，align_shift是该字节数所遵守的对齐数(以位运算中需要左移的位数表示)
	static inline size_t _Index(size_t bytes, size_t align_shift)
	{
		return ((bytes + (1 << align_shift) - 1) >> align_shift) - 1;
	}

	static inline size_t Index(size_t bytes)
	{
		assert(bytes <= MAX_BYTES);
		//每个对齐数的自由链表个数
		//static int group_freelist[4] = { 16, 56, 56, 56 };
         //用于扣除前面不属于当前对齐数的自由链表的个数
		static int group_freelist[4] = { 16, 72, 128, 184};
		if (bytes <= 128)
			return _Index(bytes, 3);	//3是2^3, 这里传的是 使用位运算要达到对齐数需要左移的位数
		else if (bytes <= 1024)
			return _Index(bytes - 128, 4) + group_freelist[0];
		else if (bytes <= 8 * 1024)
			return _Index(bytes - 8 * 1024, 7) + group_freelist[1];
		else if (bytes <= 64 * 1024)
			return _Index(bytes - 64 * 1024, 10) + group_freelist[2];
		else if (bytes <= 256 * 1024)
			return _Index(bytes - 256 * 1024, 13) + group_freelist[3];
		else
			assert(false);
		return -1;
	}
}
```

&emsp;

&emsp;

## 释放内存

**问题：什么情况下开始向上层释放内存?**

tcmalloc中给出了2个情况:

1. 判断当前的``freelist``的长度大于等于一次批量申请的内存时就开始释放freelist当前长度大小的list还给centralcache
2. 当ThreadCache整体的内存占用大小如果超过一定大小(如2M)就进行回收与释放

我们这里只考虑第一点，即：``_freelists[index].Size() >= _freelists[index].MaxSize()``

&emsp;我们释放的ptr重新放回``_freelists[index]``中, 以方便后续继续使用。当``_freelists[index]``的长度大于等于一次批量申请的小块内存的数量时*(MaxSize)*，我们就对当前所在桶的自由链表进行释放，将长度位MaxSize的链表归还给CentralCache对应的Span当中。

```cpp
void ThreadCache::Deallocate(void* ptr, size_t size)
{
	assert(ptr);
	assert(size <= MAX_BYTES);
	
	size_t index = SizeClass::Index(size);	//计算出应该插到哪个自由链表上
	_freelists[index].Push(ptr);	//将ptr这块空间头插到对应的自由链表上

	//当自由链表下面挂着的小块内存的数量 >= 一次批量申请的小块内存的数量时,
	//我们将Size()大小的小块内存全部返回给CentralCache的Span上
	if (_freelists[index].Size() >= _freelists[index].MaxSize())
	{
		ListTooLong(_freelists[index], size);
	}
}

void ThreadCache::ListTooLong(FreeList& freelist, size_t size)
{
	void* start = nullptr;
	void* end = nullptr;
	freelist.PopRange(start, end, freelist.MaxSize());	//让freelist Pop出一段区间(这里的第三个参数没什么意义, 可以考虑删除)
	CentralCache::GetInstance()->ReleaseListToSpans(start, size);
}
```

&emsp;

&emsp;

## TLS无锁访问

&emsp;我们在设计ThreadCache时，谈到了每个线程都有自己独属的ThreadCache，因此在访问ThreadCache时不需要加锁访问。那么这个独属的ThreadCache该怎么做到呢?每个线程都要去new ThreadCache对象，然而在new对象时，就可能出现多个线程同时去new，此时如果不加锁就会出问题！

&emsp;这里我们需要借助到TLS(Thread Local Storage，线程本地存储)，是一种变量的存储方法，这个变量在它所在的线程是全局可访问的，但是其它线程是不能访问的，这就保持了**数据的线程独立性**。这样就避免了锁的使用。TLS在Linux下和Windows下面的接口不同，具体参考下面的：

[Linux TLS ](https://zhuanlan.zhihu.com/p/142418922)、[Windows TLS](https://www.cnblogs.com/liu6666/p/12729014.html)

---

&emsp;这里定义一个TLS对象的指针，每个线程通过该指针去new ThreadCache对象，然后向ThreadCache申请空间。

```cpp
// TLS thread local storage
static _declspec(thread) ThreadCache* pTLSThreadCache = nullptr;
```



**问题**：为什么需要创建下面2个函数?/为什么还要封装一层?
&emsp;因为每个线程都有自己的TLS，我们不可能让用户自己去调用TLS然后才能调到Allocate，而是应该直接给他们提供接口。让他们使用接口就行了

```cpp
//封装一层
static void* ConcurrentAllocate(size_t size)	//对于tcmalloc中，这里的的名称就是tcmalloc了
{
	if (pTLSThreadCache == nullptr)
	{
		pTLSThreadCache = new ThreadCache;
	}
	cout << std::this_thread::get_id() << ":" << pTLSThreadCache << endl;
	return pTLSThreadCache->Allocate(size);
}

//封装一层
static void ConcurrentDeallocate(void* ptr, size_t size)
{
	assert(pTLSThreadCache);
	pTLSThreadCache->Deallocate(ptr, size);
}
```

&emsp;

&emsp;

# CentralCache

## 框架结构与成员变量







## 申请内存























# 项目优化

## 1. 申请对象大小大于256KB

申请对象大小的情况分类:

1. ``size <= 256KB``	--> 三层缓存, 直接向ThreadCache申请
2. ``size > 256KB`` && ``size <= ((NAPGES - 1) >> PAGE_SHIFT)`` --> 直接向PageCache申请
3. ``size > ((NPAGES - 1) >> PAGE_SHIFT)`` --> 直接向堆申请





&emsp;

## 2. 使用定长内存池取代new











&emsp;

## 3. Free对象时不传大小

&emsp;正常的free函数我们只传了一个ptr指针，并没有要求我们传递对象的大小。那么如何通过ptr指针关联到对象的大小呢?

**问题**：我们需要对象的大小去做什么? 
&emsp;通过对象的大小计算出对齐数alignNum,随后通过映射规则就能得到这个对象在删除时应该插入到哪个桶的freelist当中。

既然不传大小, 那么就代表我们需要根据我们所传的ptr指针来得到什么对象的大小!

ptr指针 --> PAGE_ID --> Span*

解决方法：

1. 我们可以建立一个PAGE_ID与对象大小Size的映射关系表
2. 我们可以在Span结构体当中增添一个新的成员变量``ObjectSize``已记录当前的Span分配对象时对象的大小。





**缺漏点**:

1. ThreahCache.cpp中的ListTooLong的PopRange中, freelist.MaxSize()作为多余的参数传了过去

2. 加锁的问题: MapPAGEIDToSpan()函数访问时的加锁问题。CentralCache中的ReleaseListToSpans中访问MapPAGEIDToSpan, 最好也加上PageCache的锁。(因为对_idSpanMap的操作都是在PageCache的锁下面操作的, 因此要加锁也必须加同一把)







# 性能优化

使用基数树替代unordered_map。









